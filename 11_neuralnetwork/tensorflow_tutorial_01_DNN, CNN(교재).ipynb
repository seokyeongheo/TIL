{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리, 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import matplotlib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-5c2caf701ebe>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# CNN 모델에 맞게 입력 이미지 형태 변경\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11ce09b00>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11c09e9b0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11c7364a8>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0, 1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱, 패딩, 풀링 적용을 위한 함수 정의\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2X2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 합성곱 계층의 가중치, 편향 정의\n",
    "\n",
    "w_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "w_conv1, b_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Relu:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
       " <tf.Tensor 'MaxPool:0' shape=(?, 14, 14, 32) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReLU 함수 및 풀링 계층 정의\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2X2(h_conv1)\n",
    "h_conv1, h_pool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 합성곱 계층의 가중치, 편향 정의\n",
    "\n",
    "w_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2X2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected net을 정의\n",
    "\n",
    "w_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "# 드랍아웃 정의\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# softmax regression을 적용하여 최종 결과값을 정의\n",
    "w_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 테스트를 통해 정확도 출력\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.07\n",
      "step 10, train accuracy 0.41\n",
      "step 20, train accuracy 0.58\n",
      "step 30, train accuracy 0.76\n",
      "step 40, train accuracy 0.79\n",
      "step 50, train accuracy 0.8\n",
      "step 60, train accuracy 0.82\n",
      "step 70, train accuracy 0.85\n",
      "step 80, train accuracy 0.87\n",
      "step 90, train accuracy 0.95\n",
      "step 100, train accuracy 0.92\n",
      "step 110, train accuracy 0.93\n",
      "step 120, train accuracy 0.9\n",
      "step 130, train accuracy 0.92\n",
      "step 140, train accuracy 0.92\n",
      "step 150, train accuracy 0.87\n",
      "step 160, train accuracy 0.89\n",
      "step 170, train accuracy 0.97\n",
      "step 180, train accuracy 0.91\n",
      "step 190, train accuracy 0.95\n",
      "step 200, train accuracy 0.93\n",
      "step 210, train accuracy 0.93\n",
      "step 220, train accuracy 0.95\n",
      "step 230, train accuracy 0.94\n",
      "step 240, train accuracy 0.95\n",
      "step 250, train accuracy 0.93\n",
      "step 260, train accuracy 0.93\n",
      "step 270, train accuracy 0.96\n",
      "step 280, train accuracy 0.93\n",
      "step 290, train accuracy 0.95\n",
      "step 300, train accuracy 0.93\n",
      "step 310, train accuracy 0.96\n",
      "step 320, train accuracy 0.95\n",
      "step 330, train accuracy 0.95\n",
      "step 340, train accuracy 0.94\n",
      "step 350, train accuracy 0.92\n",
      "step 360, train accuracy 0.92\n",
      "step 370, train accuracy 0.97\n",
      "step 380, train accuracy 0.95\n",
      "step 390, train accuracy 0.92\n",
      "step 400, train accuracy 0.92\n",
      "step 410, train accuracy 0.96\n",
      "step 420, train accuracy 0.97\n",
      "step 430, train accuracy 0.93\n",
      "step 440, train accuracy 0.95\n",
      "step 450, train accuracy 0.9\n",
      "step 460, train accuracy 0.98\n",
      "step 470, train accuracy 0.98\n",
      "step 480, train accuracy 0.93\n",
      "step 490, train accuracy 0.94\n",
      "step 500, train accuracy 0.95\n",
      "step 510, train accuracy 0.99\n",
      "step 520, train accuracy 0.98\n",
      "step 530, train accuracy 0.97\n",
      "step 540, train accuracy 0.96\n",
      "step 550, train accuracy 0.93\n",
      "step 560, train accuracy 0.99\n",
      "step 570, train accuracy 0.95\n",
      "step 580, train accuracy 0.95\n",
      "step 590, train accuracy 0.98\n",
      "step 600, train accuracy 0.97\n",
      "step 610, train accuracy 0.97\n",
      "step 620, train accuracy 0.96\n",
      "step 630, train accuracy 0.96\n",
      "step 640, train accuracy 0.98\n",
      "step 650, train accuracy 0.94\n",
      "step 660, train accuracy 0.96\n",
      "step 670, train accuracy 0.94\n",
      "step 680, train accuracy 0.96\n",
      "step 690, train accuracy 0.98\n",
      "step 700, train accuracy 0.96\n",
      "step 710, train accuracy 0.98\n",
      "step 720, train accuracy 0.98\n",
      "step 730, train accuracy 1\n",
      "step 740, train accuracy 0.98\n",
      "step 750, train accuracy 0.97\n",
      "step 760, train accuracy 0.98\n",
      "step 770, train accuracy 0.96\n",
      "step 780, train accuracy 0.98\n",
      "step 790, train accuracy 0.96\n",
      "step 800, train accuracy 0.98\n",
      "step 810, train accuracy 0.96\n",
      "step 820, train accuracy 0.97\n",
      "step 830, train accuracy 0.97\n",
      "step 840, train accuracy 0.94\n",
      "step 850, train accuracy 0.99\n",
      "step 860, train accuracy 0.94\n",
      "step 870, train accuracy 0.98\n",
      "step 880, train accuracy 0.98\n",
      "step 890, train accuracy 0.98\n",
      "step 900, train accuracy 0.97\n",
      "step 910, train accuracy 0.97\n",
      "step 920, train accuracy 0.97\n",
      "step 930, train accuracy 0.95\n",
      "step 940, train accuracy 0.98\n",
      "step 950, train accuracy 0.97\n",
      "step 960, train accuracy 1\n",
      "step 970, train accuracy 0.95\n",
      "step 980, train accuracy 0.96\n",
      "step 990, train accuracy 0.99\n",
      "step 1000, train accuracy 0.97\n",
      "step 1010, train accuracy 0.97\n",
      "step 1020, train accuracy 0.99\n",
      "step 1030, train accuracy 0.95\n",
      "step 1040, train accuracy 0.96\n",
      "step 1050, train accuracy 0.96\n",
      "step 1060, train accuracy 0.97\n",
      "step 1070, train accuracy 0.97\n",
      "step 1080, train accuracy 0.97\n",
      "step 1090, train accuracy 0.97\n",
      "step 1100, train accuracy 0.98\n",
      "step 1110, train accuracy 1\n",
      "step 1120, train accuracy 0.99\n",
      "step 1130, train accuracy 1\n",
      "step 1140, train accuracy 0.98\n",
      "step 1150, train accuracy 0.96\n",
      "step 1160, train accuracy 0.98\n",
      "step 1170, train accuracy 0.98\n",
      "step 1180, train accuracy 0.97\n",
      "step 1190, train accuracy 0.99\n",
      "step 1200, train accuracy 0.98\n",
      "step 1210, train accuracy 0.99\n",
      "step 1220, train accuracy 0.99\n",
      "step 1230, train accuracy 0.95\n",
      "step 1240, train accuracy 0.97\n",
      "step 1250, train accuracy 1\n",
      "step 1260, train accuracy 0.98\n",
      "step 1270, train accuracy 0.98\n",
      "step 1280, train accuracy 0.96\n",
      "step 1290, train accuracy 0.96\n",
      "step 1300, train accuracy 0.98\n",
      "step 1310, train accuracy 0.98\n",
      "step 1320, train accuracy 0.98\n",
      "step 1330, train accuracy 1\n",
      "step 1340, train accuracy 0.97\n",
      "step 1350, train accuracy 0.98\n",
      "step 1360, train accuracy 0.98\n",
      "step 1370, train accuracy 0.98\n",
      "step 1380, train accuracy 1\n",
      "step 1390, train accuracy 0.99\n",
      "step 1400, train accuracy 0.99\n",
      "step 1410, train accuracy 0.99\n",
      "step 1420, train accuracy 0.99\n",
      "step 1430, train accuracy 0.98\n",
      "step 1440, train accuracy 0.99\n",
      "step 1450, train accuracy 0.99\n",
      "step 1460, train accuracy 0.98\n",
      "step 1470, train accuracy 0.99\n",
      "step 1480, train accuracy 0.98\n",
      "step 1490, train accuracy 0.97\n",
      "step 1500, train accuracy 0.99\n",
      "step 1510, train accuracy 0.99\n",
      "step 1520, train accuracy 1\n",
      "step 1530, train accuracy 0.99\n",
      "step 1540, train accuracy 0.95\n",
      "step 1550, train accuracy 1\n",
      "step 1560, train accuracy 0.96\n",
      "step 1570, train accuracy 0.99\n",
      "step 1580, train accuracy 0.96\n",
      "step 1590, train accuracy 0.98\n",
      "step 1600, train accuracy 0.98\n",
      "step 1610, train accuracy 1\n",
      "step 1620, train accuracy 1\n",
      "step 1630, train accuracy 1\n",
      "step 1640, train accuracy 0.99\n",
      "step 1650, train accuracy 1\n",
      "step 1660, train accuracy 0.96\n",
      "step 1670, train accuracy 0.98\n",
      "step 1680, train accuracy 0.98\n",
      "step 1690, train accuracy 0.99\n",
      "step 1700, train accuracy 0.98\n",
      "step 1710, train accuracy 0.97\n",
      "step 1720, train accuracy 0.98\n",
      "step 1730, train accuracy 0.98\n",
      "step 1740, train accuracy 1\n",
      "step 1750, train accuracy 0.98\n",
      "step 1760, train accuracy 0.98\n",
      "step 1770, train accuracy 1\n",
      "step 1780, train accuracy 1\n",
      "step 1790, train accuracy 1\n",
      "step 1800, train accuracy 0.98\n",
      "step 1810, train accuracy 0.99\n",
      "step 1820, train accuracy 0.97\n",
      "step 1830, train accuracy 0.98\n",
      "step 1840, train accuracy 0.97\n",
      "step 1850, train accuracy 0.97\n",
      "step 1860, train accuracy 0.99\n",
      "step 1870, train accuracy 0.95\n",
      "step 1880, train accuracy 1\n",
      "step 1890, train accuracy 0.99\n",
      "step 1900, train accuracy 0.97\n",
      "step 1910, train accuracy 1\n",
      "step 1920, train accuracy 0.99\n",
      "step 1930, train accuracy 0.97\n",
      "step 1940, train accuracy 0.99\n",
      "step 1950, train accuracy 1\n",
      "step 1960, train accuracy 0.98\n",
      "step 1970, train accuracy 0.99\n",
      "step 1980, train accuracy 0.99\n",
      "step 1990, train accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(2000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 10 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={\n",
    "            x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, train accuracy %g\" % (i, train_accuracy))\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.982\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\" % sess.run(accuracy, feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN - single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지와 라벨 값 정의\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 가중치와 편향 정의\n",
    "\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 출력값 정의\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "\n",
    "# 손실 함수 정의\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# 추정 방법(경사 하강법) 정의\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 변수 초기화, 세션 시작\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN - multi layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight & bias initialization\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0, 1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 은닉 계층의 가중치, 편향 정의\n",
    "w_1 = weight_variable([784, 360])\n",
    "b_1 = bias_variable([360])\n",
    "\n",
    "# ReLU 함수 적용\n",
    "h_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)\n",
    "\n",
    "# 두번째 은닉 계층의 가중치, 편향 정의\n",
    "w_2 = weight_variable([360, 180])\n",
    "b_2 = bias_variable([180])\n",
    "\n",
    "# ReLU 함수 정의\n",
    "h_2 = tf.nn.relu(tf.matmul(h_1, w_2) + b_2)\n",
    "\n",
    "# 세번째 은닉 계층의 가중치, 편향 정의\n",
    "w_3 = weight_variable([180, 10])\n",
    "b_3 = bias_variable([10])\n",
    "\n",
    "# 소프트맥스 함수 적용\n",
    "y = tf.nn.softmax(tf.matmul(h_2, w_3) + b_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 및 추정방법, 기타 함수 정의\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 모든 변수 초기화, 세션 시작\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 1000번의 반복 학습 후 최종 예측값 및 정확도 출력\n",
    "\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
