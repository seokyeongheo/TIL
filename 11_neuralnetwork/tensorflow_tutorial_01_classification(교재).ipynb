{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], \n",
    "                   [4, 1, 5, 5], [1, 7, 5, 5], [1, 2, 5, 6], \n",
    "                   [1, 6, 6, 6], [1, 7, 7, 7]])\n",
    "\n",
    "y_data = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], \n",
    "                   [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]])\n",
    "\n",
    "X = tf.placeholder('float', [None, 4])\n",
    "Y = tf.placeholder('float', [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes], name='bias'))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 4),\n",
       " (8, 3),\n",
       " TensorShape([Dimension(4), Dimension(3)]),\n",
       " TensorShape([Dimension(3)]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape, W.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.797593\n",
      "200 0.57750267\n",
      "400 0.4704681\n",
      "600 0.3745716\n",
      "800 0.2835989\n",
      "1000 0.23747563\n",
      "1200 0.2149789\n",
      "1400 0.19629832\n",
      "1600 0.18052256\n",
      "1800 0.1670222\n",
      "2000 0.15534174\n",
      "[[7.7862656e-03 9.9220616e-01 7.6045153e-06]] [1]\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수, 최적화 알고리즘 정의\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cross_entropy)\n",
    "\n",
    "# 모델링\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train_step, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(cross_entropy, feed_dict={X: x_data, Y: y_data}))\n",
    "            \n",
    "a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\n",
    "print(a, sess.run(tf.arg_max(a, 1)))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animal classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101, 17), (101, 16), (101, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape, x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [6.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [0.],\n",
       "       [6.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "y_ = tf.nn.softmax(logits)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(y_, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0 | Loss: 6.280 | Acc: 15.84%\n",
      "Step:   100 | Loss: 0.841 | Acc: 77.23%\n",
      "Step:   200 | Loss: 0.484 | Acc: 85.15%\n",
      "Step:   300 | Loss: 0.315 | Acc: 90.10%\n",
      "Step:   400 | Loss: 0.231 | Acc: 96.04%\n",
      "Step:   500 | Loss: 0.186 | Acc: 97.03%\n",
      "Step:   600 | Loss: 0.156 | Acc: 99.01%\n",
      "Step:   700 | Loss: 0.136 | Acc: 99.01%\n",
      "Step:   800 | Loss: 0.120 | Acc: 99.01%\n",
      "Step:   900 | Loss: 0.107 | Acc: 99.01%\n",
      "Step:  1000 | Loss: 0.097 | Acc: 100.00%\n",
      "Step:  1100 | Loss: 0.089 | Acc: 100.00%\n",
      "Step:  1200 | Loss: 0.082 | Acc: 100.00%\n",
      "Step:  1300 | Loss: 0.076 | Acc: 100.00%\n",
      "Step:  1400 | Loss: 0.071 | Acc: 100.00%\n",
      "Step:  1500 | Loss: 0.066 | Acc: 100.00%\n",
      "Step:  1600 | Loss: 0.062 | Acc: 100.00%\n",
      "Step:  1700 | Loss: 0.059 | Acc: 100.00%\n",
      "Step:  1800 | Loss: 0.056 | Acc: 100.00%\n",
      "Step:  1900 | Loss: 0.053 | Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000):\n",
    "    sess.run(train_step, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "        print(\"Step: {:5} | Loss: {:.3f} | Acc: {:.2%}\".format(step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "\n",
    "for p, y in zip(pred, y_data.flatten()):\n",
    "    print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5], \n",
    "                  [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]])\n",
    "\n",
    "y_data = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], \n",
    "                  [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]])\n",
    "\n",
    "x_test = np.array([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n",
    "y_test = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 1]])\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_), axis=1))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(y_, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 15.198463439941406\n",
      "1, 13.581802368164062\n",
      "2, 11.977788925170898\n",
      "3, 10.40011215209961\n",
      "4, 8.867838859558105\n",
      "5, 7.409326076507568\n",
      "6, 6.081491470336914\n",
      "7, 5.04601526260376\n",
      "8, 4.649823188781738\n",
      "9, 4.654688835144043\n",
      "10, 4.555233001708984\n",
      "11, 4.295168876647949\n",
      "12, 3.9172675609588623\n",
      "13, 3.4776341915130615\n",
      "14, 3.0675673484802246\n",
      "15, 2.908010959625244\n",
      "16, 3.1819801330566406\n",
      "17, 3.5470123291015625\n",
      "18, 3.7452950477600098\n",
      "19, 3.7470502853393555\n",
      "20, 3.578122138977051\n",
      "21, 3.2774274349212646\n",
      "22, 2.8991880416870117\n",
      "23, 2.530768632888794\n",
      "24, 2.286210060119629\n",
      "25, 2.2064881324768066\n",
      "26, 2.219404697418213\n",
      "27, 2.2496800422668457\n",
      "28, 2.27140212059021\n",
      "29, 2.2884743213653564\n",
      "30, 2.3053557872772217\n",
      "31, 2.311870574951172\n",
      "32, 2.2893929481506348\n",
      "33, 2.224886178970337\n",
      "34, 2.1186459064483643\n",
      "35, 1.985011100769043\n",
      "36, 1.8488638401031494\n",
      "37, 1.7378747463226318\n",
      "38, 1.6710975170135498\n",
      "39, 1.6498138904571533\n",
      "40, 1.6574426889419556\n",
      "41, 1.6691546440124512\n",
      "42, 1.6646407842636108\n",
      "43, 1.6355952024459839\n",
      "44, 1.585569143295288\n",
      "45, 1.524820327758789\n",
      "46, 1.4634901285171509\n",
      "47, 1.4069923162460327\n",
      "48, 1.3565045595169067\n",
      "49, 1.3127830028533936\n",
      "50, 1.2782258987426758\n",
      "51, 1.2544922828674316\n",
      "52, 1.23846435546875\n",
      "53, 1.222139596939087\n",
      "54, 1.1977510452270508\n",
      "55, 1.1631413698196411\n",
      "56, 1.1226420402526855\n",
      "57, 1.083404779434204\n",
      "58, 1.0506707429885864\n",
      "59, 1.02561616897583\n",
      "60, 1.0063430070877075\n",
      "61, 0.9899123907089233\n",
      "62, 0.9737163186073303\n",
      "63, 0.9560261964797974\n",
      "64, 0.9361695051193237\n",
      "65, 0.9145505428314209\n",
      "66, 0.8924535512924194\n",
      "67, 0.8715577721595764\n",
      "68, 0.8532728552818298\n",
      "69, 0.8381751179695129\n",
      "70, 0.8258168697357178\n",
      "71, 0.8150133490562439\n",
      "72, 0.804449200630188\n",
      "73, 0.793277382850647\n",
      "74, 0.78139328956604\n",
      "75, 0.7692846059799194\n",
      "76, 0.7576227188110352\n",
      "77, 0.7468917965888977\n",
      "78, 0.7372498512268066\n",
      "79, 0.7286086082458496\n",
      "80, 0.7207766175270081\n",
      "81, 0.7135428190231323\n",
      "82, 0.7066906690597534\n",
      "83, 0.7000086307525635\n",
      "84, 0.6933391094207764\n",
      "85, 0.6866426467895508\n",
      "86, 0.6800166368484497\n",
      "87, 0.6736404895782471\n",
      "88, 0.6676760315895081\n",
      "89, 0.6621868014335632\n",
      "90, 0.6571217775344849\n",
      "91, 0.6523618102073669\n",
      "92, 0.6477861404418945\n",
      "93, 0.6433166265487671\n",
      "94, 0.6389238238334656\n",
      "95, 0.634608268737793\n",
      "96, 0.6303811073303223\n",
      "97, 0.6262570023536682\n",
      "98, 0.6222565174102783\n",
      "99, 0.6184048652648926\n",
      "100, 0.6147215366363525\n",
      "101, 0.6112062931060791\n",
      "102, 0.6078328490257263\n",
      "103, 0.6045590043067932\n",
      "104, 0.6013460159301758\n",
      "105, 0.5981744527816772\n",
      "106, 0.5950461030006409\n",
      "107, 0.5919738411903381\n",
      "108, 0.5889692902565002\n",
      "109, 0.5860366225242615\n",
      "110, 0.5831754207611084\n",
      "111, 0.5803840160369873\n",
      "112, 0.5776610374450684\n",
      "113, 0.5750027894973755\n",
      "114, 0.5724009275436401\n",
      "115, 0.5698438882827759\n",
      "116, 0.5673211812973022\n",
      "117, 0.5648286938667297\n",
      "118, 0.5623685717582703\n",
      "119, 0.5599460601806641\n",
      "120, 0.5575646162033081\n",
      "121, 0.5552244186401367\n",
      "122, 0.5529230833053589\n",
      "123, 0.5506576299667358\n",
      "124, 0.5484262704849243\n",
      "125, 0.5462266802787781\n",
      "126, 0.544056236743927\n",
      "127, 0.5419116616249084\n",
      "128, 0.5397905111312866\n",
      "129, 0.5376920700073242\n",
      "130, 0.5356173515319824\n",
      "131, 0.5335677862167358\n",
      "132, 0.5315434336662292\n",
      "133, 0.5295437574386597\n",
      "134, 0.5275670886039734\n",
      "135, 0.5256123542785645\n",
      "136, 0.5236784219741821\n",
      "137, 0.5217646360397339\n",
      "138, 0.519869863986969\n",
      "139, 0.5179930925369263\n",
      "140, 0.5161336660385132\n",
      "141, 0.514291524887085\n",
      "142, 0.5124668478965759\n",
      "143, 0.5106598138809204\n",
      "144, 0.5088698863983154\n",
      "145, 0.5070967078208923\n",
      "146, 0.5053393840789795\n",
      "147, 0.5035973787307739\n",
      "148, 0.5018704533576965\n",
      "149, 0.5001580119132996\n",
      "150, 0.49845975637435913\n",
      "151, 0.49677520990371704\n",
      "152, 0.49510419368743896\n",
      "153, 0.4934467077255249\n",
      "154, 0.49180251359939575\n",
      "155, 0.49017155170440674\n",
      "156, 0.4885534346103668\n",
      "157, 0.48694780468940735\n",
      "158, 0.4853544235229492\n",
      "159, 0.4837730824947357\n",
      "160, 0.48220351338386536\n",
      "161, 0.48064547777175903\n",
      "162, 0.4790987968444824\n",
      "163, 0.47756320238113403\n",
      "164, 0.4760386049747467\n",
      "165, 0.47452500462532043\n",
      "166, 0.47302210330963135\n",
      "167, 0.47152984142303467\n",
      "168, 0.4700479507446289\n",
      "169, 0.46857622265815735\n",
      "170, 0.46711456775665283\n",
      "171, 0.46566277742385864\n",
      "172, 0.46422079205513\n",
      "173, 0.4627884030342102\n",
      "174, 0.4613655209541321\n",
      "175, 0.45995205640792847\n",
      "176, 0.45854777097702026\n",
      "177, 0.45715272426605225\n",
      "178, 0.4557666778564453\n",
      "179, 0.45438963174819946\n",
      "180, 0.4530213475227356\n",
      "181, 0.45166173577308655\n",
      "182, 0.45031070709228516\n",
      "183, 0.44896817207336426\n",
      "184, 0.4476340115070343\n",
      "185, 0.4463081359863281\n",
      "186, 0.4449903964996338\n",
      "187, 0.4436808228492737\n",
      "188, 0.442379355430603\n",
      "189, 0.44108572602272034\n",
      "190, 0.439799964427948\n",
      "191, 0.43852195143699646\n",
      "192, 0.43725156784057617\n",
      "193, 0.4359889030456543\n",
      "194, 0.43473362922668457\n",
      "195, 0.43348589539527893\n",
      "196, 0.4322454333305359\n",
      "197, 0.43101227283477783\n",
      "198, 0.4297863841056824\n",
      "199, 0.4285675883293152\n",
      "200, 0.4273558557033539\n",
      "Prediction : [2 2 2]\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(201):\n",
    "        cost_val, W_val = sess.run([cost, train_step], feed_dict={X: x_data, Y: y_data})\n",
    "        print(\"{}, {}\".format(step, cost_val))\n",
    "        \n",
    "    print(\"Prediction : {}\".format(sess.run(prediction, feed_dict={X: x_test})))\n",
    "    print(\"Accuracy : {}\".format(sess.run(accuracy, feed_dict={X: x_test, Y: y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
